{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1337)  \n",
    "from keras.preprocessing import sequence\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threat</th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   threat  duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
       "0       0         0              1        1     1        181       5450     0   \n",
       "1       0         0              1        1     1        239        486     0   \n",
       "2       0         0              1        1     1        235       1337     0   \n",
       "3       0         0              1        1     1        219       1337     0   \n",
       "4       0         0              1        1     1        217       2032     0   \n",
       "\n",
       "   wrong_fragment  urgent  ...  dst_host_count  dst_host_srv_count  \\\n",
       "0               0       0  ...               9                   9   \n",
       "1               0       0  ...              19                  19   \n",
       "2               0       0  ...              29                  29   \n",
       "3               0       0  ...              39                  39   \n",
       "4               0       0  ...              49                  49   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                     1.0                     0.0   \n",
       "1                     1.0                     0.0   \n",
       "2                     1.0                     0.0   \n",
       "3                     1.0                     0.0   \n",
       "4                     1.0                     0.0   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.11                          0.0   \n",
       "1                         0.05                          0.0   \n",
       "2                         0.03                          0.0   \n",
       "3                         0.03                          0.0   \n",
       "4                         0.02                          0.0   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                   0.0   \n",
       "1                   0.0                       0.0                   0.0   \n",
       "2                   0.0                       0.0                   0.0   \n",
       "3                   0.0                       0.0                   0.0   \n",
       "4                   0.0                       0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata = pd.read_csv('kddtrain.csv', header=None)\n",
    "traindata.columns= [\"threat\", \"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\"\n",
    "                         ,\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\", \n",
    "                          \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\"\n",
    "                         ,\"num_shells\", \"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\"\n",
    "                         ,\"count\", \"srv_count\",\"serror_rate\", \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\"\n",
    "                         ,\"same_srv_rate\",\"diff_srv_rate\", \"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\"\n",
    "                         ,\"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\"\n",
    "                         ,\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\"]\n",
    "testdata = pd.read_csv('kddtest.csv', header=None)\n",
    "testdata.columns = traindata.columns\n",
    "traindata = traindata.drop(columns = [\"num_outbound_cmds\",\"is_host_login\"])\n",
    "testdata = testdata.drop(columns = [\"num_outbound_cmds\",\"is_host_login\"])\n",
    "traindata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1120x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 6), dpi=80)\n",
    "for i in range(6):\n",
    "    ax.plot(traindata[traindata.columns[i]], label=traindata.columns[i], linewidth=1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311029, 40)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainvalues = traindata.values\n",
    "trainvalues = trainvalues.astype('float32')\n",
    "testvalues = testdata.values\n",
    "testvalues = testvalues.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "trainvalues = scaler.fit_transform(trainvalues)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "testvalues = scaler.fit_transform(testvalues)\n",
    "\n",
    "traindataset = trainvalues[0:len(trainvalues),:]\n",
    "testdataset = testvalues[0:len(testvalues),:]\n",
    "\n",
    "batch_size = 64\n",
    "testdataset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, timestep=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-timestep-1):\n",
    "        a = dataset[i:(i+timestep), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + timestep, :])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var10(t-1)</th>\n",
       "      <th>...</th>\n",
       "      <th>var32(t-1)</th>\n",
       "      <th>var33(t-1)</th>\n",
       "      <th>var34(t-1)</th>\n",
       "      <th>var35(t-1)</th>\n",
       "      <th>var36(t-1)</th>\n",
       "      <th>var37(t-1)</th>\n",
       "      <th>var38(t-1)</th>\n",
       "      <th>var39(t-1)</th>\n",
       "      <th>var40(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.610418e-07</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.446905e-07</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.389216e-07</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)     var6(t-1)  \\\n",
       "1        0.0        0.0        0.0        0.0        0.0  2.610418e-07   \n",
       "2        0.0        0.0        0.0        0.0        0.0  3.446905e-07   \n",
       "3        0.0        0.0        0.0        0.0        0.0  3.389216e-07   \n",
       "\n",
       "   var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  ...  var32(t-1)  var33(t-1)  \\\n",
       "1   0.001057        0.0        0.0         0.0  ...    0.035294         1.0   \n",
       "2   0.000094        0.0        0.0         0.0  ...    0.074510         1.0   \n",
       "3   0.000259        0.0        0.0         0.0  ...    0.113725         1.0   \n",
       "\n",
       "   var34(t-1)  var35(t-1)  var36(t-1)  var37(t-1)  var38(t-1)  var39(t-1)  \\\n",
       "1         0.0        0.11         0.0         0.0         0.0         0.0   \n",
       "2         0.0        0.05         0.0         0.0         0.0         0.0   \n",
       "3         0.0        0.03         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   var40(t-1)  var1(t)  \n",
       "1         0.0      0.0  \n",
       "2         0.0      0.0  \n",
       "3         0.0      0.0  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframedtrain = series_to_supervised(traindataset)\n",
    "reframedtrain.drop(reframedtrain.columns[list(i for i in range(41, 80))], axis=1, inplace=True)\n",
    "reframedtest = series_to_supervised(testdataset)\n",
    "reframedtest.drop(reframedtest.columns[list(i for i in range(41, 80))], axis=1, inplace=True)\n",
    "reframedtrain[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494020, 40)\n",
      "(494020,)\n",
      "(494020, 1, 40) (494020,) (311028, 1, 40) (311028,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep = 1\n",
    "#trainX, trainY = create_dataset(traindataset, timestep)\n",
    "#testX, testY = create_dataset(testdataset, timestep)\n",
    "valuestrain = reframedtrain.values\n",
    "valuestest = reframedtest.values\n",
    "trainX, trainY = valuestrain[:,:-1], valuestrain[:,-1]\n",
    "testX, testY = valuestest[:,:-1], valuestest[:,-1]\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_lambda = 0.0001\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(trainX.shape[1], trainX.shape[2]), kernel_regularizer=l2(l2_lambda), dropout=0.01 ,recurrent_dropout=0.01, return_sequences=True))\n",
    "model.add(Dense(256, kernel_regularizer=l2(l2_lambda), activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, kernel_regularizer=l2(l2_lambda)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7720/7720 - 26s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3886 - val_accuracy: 0.9438\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.00595, saving model to C:/Users/Shigatau/Documents/Диплом/Intrusion-Detection-Systems-master/dnn/kddresults/LSTM\\check.hdf5\n",
      "Epoch 2/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3853 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00595\n",
      "Epoch 3/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3764 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00595\n",
      "Epoch 4/100\n",
      "7720/7720 - 23s - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.3733 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 00004: loss improved from 0.00595 to 0.00590, saving model to C:/Users/Shigatau/Documents/Диплом/Intrusion-Detection-Systems-master/dnn/kddresults/LSTM\\check.hdf5\n",
      "Epoch 5/100\n",
      "7720/7720 - 23s - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.3592 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00590\n",
      "Epoch 6/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3704 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00590\n",
      "Epoch 7/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3740 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00590\n",
      "Epoch 8/100\n",
      "7720/7720 - 22s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.3598 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00590\n",
      "Epoch 9/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3733 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00590\n",
      "Epoch 10/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3686 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00590\n",
      "Epoch 11/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.4184 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00590\n",
      "Epoch 12/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.4083 - val_accuracy: 0.9433\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00590\n",
      "Epoch 13/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3947 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00590\n",
      "Epoch 14/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.4183 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00590\n",
      "Epoch 15/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3929 - val_accuracy: 0.9430\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00590\n",
      "Epoch 16/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3703 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00590\n",
      "Epoch 17/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.4178 - val_accuracy: 0.9427\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00590\n",
      "Epoch 18/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3707 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00590\n",
      "Epoch 19/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3973 - val_accuracy: 0.9388\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00590\n",
      "Epoch 20/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3895 - val_accuracy: 0.9419\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00590\n",
      "Epoch 21/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.4096 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00590\n",
      "Epoch 22/100\n",
      "7720/7720 - 23s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.3956 - val_accuracy: 0.9430\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00590\n",
      "Epoch 23/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3701 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00590\n",
      "Epoch 24/100\n",
      "7720/7720 - 23s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.3721 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00590\n",
      "Epoch 25/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3647 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00590\n",
      "Epoch 26/100\n",
      "7720/7720 - 24s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.4084 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00590\n",
      "Epoch 27/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3830 - val_accuracy: 0.9432\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00590\n",
      "Epoch 28/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3549 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00590\n",
      "Epoch 29/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3698 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00590\n",
      "Epoch 30/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3813 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00590\n",
      "Epoch 31/100\n",
      "7720/7720 - 23s - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.3828 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00590\n",
      "Epoch 32/100\n",
      "7720/7720 - 23s - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.3783 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00590\n",
      "Epoch 33/100\n",
      "7720/7720 - 23s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.4053 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00590\n",
      "Epoch 34/100\n",
      "7720/7720 - 23s - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.3721 - val_accuracy: 0.9433\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00590\n",
      "Epoch 35/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3844 - val_accuracy: 0.9438\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00590\n",
      "Epoch 36/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3634 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00590\n",
      "Epoch 37/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3873 - val_accuracy: 0.9435\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00590\n",
      "Epoch 38/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3833 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00590\n",
      "Epoch 39/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3751 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00590\n",
      "Epoch 40/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3852 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00590\n",
      "Epoch 41/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3664 - val_accuracy: 0.9438\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00590\n",
      "Epoch 42/100\n",
      "7720/7720 - 23s - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.3734 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00590\n",
      "Epoch 43/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3860 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00590\n",
      "Epoch 44/100\n",
      "7720/7720 - 27s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.8239 - val_accuracy: 0.7801\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00590\n",
      "Epoch 45/100\n",
      "7720/7720 - 24s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3617 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00590\n",
      "Epoch 46/100\n",
      "7720/7720 - 24s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3728 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00590\n",
      "Epoch 47/100\n",
      "7720/7720 - 24s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3880 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00590\n",
      "Epoch 48/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3565 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00590\n",
      "Epoch 49/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3849 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00590\n",
      "Epoch 50/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3705 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00590\n",
      "Epoch 51/100\n",
      "7720/7720 - 23s - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.3760 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.00590\n",
      "Epoch 52/100\n",
      "7720/7720 - 24s - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.3899 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.00590\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3577 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.00590\n",
      "Epoch 54/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3818 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.00590\n",
      "Epoch 55/100\n",
      "7720/7720 - 25s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3582 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.00590\n",
      "Epoch 56/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3948 - val_accuracy: 0.9432\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.00590\n",
      "Epoch 57/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3816 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.00590\n",
      "Epoch 58/100\n",
      "7720/7720 - 23s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3774 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.00590\n",
      "Epoch 59/100\n",
      "7720/7720 - 23s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.3899 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00059: loss improved from 0.00590 to 0.00589, saving model to C:/Users/Shigatau/Documents/Диплом/Intrusion-Detection-Systems-master/dnn/kddresults/LSTM\\check.hdf5\n",
      "Epoch 60/100\n",
      "7720/7720 - 22s - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.3762 - val_accuracy: 0.9434\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.00589\n",
      "Epoch 61/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3874 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.00589\n",
      "Epoch 62/100\n",
      "7720/7720 - 23s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.3763 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.00589\n",
      "Epoch 63/100\n",
      "7720/7720 - 23s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.3804 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00063: loss improved from 0.00589 to 0.00586, saving model to C:/Users/Shigatau/Documents/Диплом/Intrusion-Detection-Systems-master/dnn/kddresults/LSTM\\check.hdf5\n",
      "Epoch 64/100\n",
      "7720/7720 - 23s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.3949 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.00586\n",
      "Epoch 65/100\n",
      "7720/7720 - 23s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.3955 - val_accuracy: 0.9440\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.00586\n",
      "Epoch 66/100\n",
      "7720/7720 - 22s - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.3831 - val_accuracy: 0.9434\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.00586\n",
      "Epoch 67/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3659 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00067: loss did not improve from 0.00586\n",
      "Epoch 68/100\n",
      "7720/7720 - 22s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3736 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.00586\n",
      "Epoch 69/100\n",
      "7720/7720 - 30s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3601 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.00586\n",
      "Epoch 70/100\n",
      "7720/7720 - 33s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.4007 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.00586\n",
      "Epoch 71/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3403 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.00586\n",
      "Epoch 72/100\n",
      "7720/7720 - 32s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.3800 - val_accuracy: 0.9445\n",
      "\n",
      "Epoch 00072: loss did not improve from 0.00586\n",
      "Epoch 73/100\n",
      "7720/7720 - 33s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3845 - val_accuracy: 0.9433\n",
      "\n",
      "Epoch 00073: loss did not improve from 0.00586\n",
      "Epoch 74/100\n",
      "7720/7720 - 32s - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.4211 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00074: loss did not improve from 0.00586\n",
      "Epoch 75/100\n",
      "7720/7720 - 31s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.6926 - val_accuracy: 0.8060\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.00586\n",
      "Epoch 76/100\n",
      "7720/7720 - 31s - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.3671 - val_accuracy: 0.9433\n",
      "\n",
      "Epoch 00076: loss did not improve from 0.00586\n",
      "Epoch 77/100\n",
      "7720/7720 - 32s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.3697 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.00586\n",
      "Epoch 78/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3631 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00078: loss did not improve from 0.00586\n",
      "Epoch 79/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3590 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.00586\n",
      "Epoch 80/100\n",
      "7720/7720 - 34s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3690 - val_accuracy: 0.9428\n",
      "\n",
      "Epoch 00080: loss did not improve from 0.00586\n",
      "Epoch 81/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3510 - val_accuracy: 0.9433\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.00586\n",
      "Epoch 82/100\n",
      "7720/7720 - 33s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3858 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00082: loss did not improve from 0.00586\n",
      "Epoch 83/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3839 - val_accuracy: 0.9408\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.00586\n",
      "Epoch 84/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3893 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.00586\n",
      "Epoch 85/100\n",
      "7720/7720 - 31s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3908 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.00586\n",
      "Epoch 86/100\n",
      "7720/7720 - 32s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.4301 - val_accuracy: 0.9425\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.00586\n",
      "Epoch 87/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3698 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.00586\n",
      "Epoch 88/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3503 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00088: loss did not improve from 0.00586\n",
      "Epoch 89/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3743 - val_accuracy: 0.9450\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.00586\n",
      "Epoch 90/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.4100 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00090: loss did not improve from 0.00586\n",
      "Epoch 91/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3761 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.00586\n",
      "Epoch 92/100\n",
      "7720/7720 - 33s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.4400 - val_accuracy: 0.9427\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.00586\n",
      "Epoch 93/100\n",
      "7720/7720 - 32s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3706 - val_accuracy: 0.9432\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.00586\n",
      "Epoch 94/100\n",
      "7720/7720 - 32s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.3899 - val_accuracy: 0.9439\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.00586\n",
      "Epoch 95/100\n",
      "7720/7720 - 31s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3837 - val_accuracy: 0.9438\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.00586\n",
      "Epoch 96/100\n",
      "7720/7720 - 30s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.3790 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.00586\n",
      "Epoch 97/100\n",
      "7720/7720 - 31s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.7229 - val_accuracy: 0.8094\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.00586\n",
      "Epoch 98/100\n",
      "7720/7720 - 31s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3723 - val_accuracy: 0.9432\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.00586\n",
      "Epoch 99/100\n",
      "7720/7720 - 30s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.3613 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.00586\n",
      "Epoch 100/100\n",
      "7720/7720 - 30s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.4730 - val_accuracy: 0.9180\n",
      "\n",
      "Epoch 00100: loss did not improve from 0.00586\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"C:/Users/Shigatau/Documents/Диплом/Intrusion-Detection-Systems-master/dnn/kddresults/LSTM/check.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('C:/Users/Shigatau/Documents/Диплом/Intrusion-Detection-Systems-master/dnn/kddresults/LSTM/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "history = model.fit(trainX, trainY,  batch_size=batch_size,validation_data=(testX, testY), verbose=2, epochs=100, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"C:/Users/Shigatau/Documents/Диплом/dnn/kddresults/LSTM/dnn3layer_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "accuracy\n",
      "0.918\n",
      "recall\n",
      "0.972\n",
      "precision\n",
      "0.929\n",
      "f1score\n",
      "0.950\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "name = []\n",
    "from numpy import concatenate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "for file in os.listdir(\"C:/Users/Shigatau/Documents/Диплом/dnn/kddresults/LSTM/\"):\n",
    "    model.load_weights(\"C:/Users/Shigatau/Documents/Диплом/dnn/kddresults/LSTM/\"+file)\n",
    "    yhat = model.predict(testX)\n",
    "    testX1 = testX.reshape((testX.shape[0], testX.shape[2]))\n",
    "    yhat = yhat.reshape((yhat.shape[0], yhat.shape[2]))\n",
    "    inv_yhat = concatenate((yhat, testX1[:, 1:]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,0]\n",
    "    # invert scaling for actual\n",
    "    testY = testY.reshape((len(testY), 1))\n",
    "    inv_y = concatenate((testY, testX1[:, 1:]), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,0]\n",
    "    for i in range(len(inv_yhat)):\n",
    "        if inv_yhat[i]>0.5:\n",
    "            inv_yhat[i] = 1\n",
    "        else:\n",
    "            inv_yhat[i] = 0\n",
    "    accuracy = accuracy_score(inv_y, inv_yhat)\n",
    "    recall = recall_score(inv_y, inv_yhat , average=\"binary\")\n",
    "    precision = precision_score(inv_y, inv_yhat , average=\"binary\")\n",
    "    f1 = f1_score(inv_y, inv_yhat, average=\"binary\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"accuracy\")\n",
    "    print(\"%.3f\" %accuracy)\n",
    "    print(\"recall\")\n",
    "    print(\"%.3f\" %recall)\n",
    "    print(\"precision\")\n",
    "    print(\"%.3f\" %precision)\n",
    "    print(\"f1score\")\n",
    "    print(\"%.3f\" %f1)\n",
    "    score.append(accuracy)\n",
    "    name.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"C:/Users/Shigatau/Documents/Диплом/Intrusion-Detection-Systems-master/dnn/dnnres/LSTMpredicted.txt\", inv_yhat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
